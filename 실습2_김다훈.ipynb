{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e312958c",
   "metadata": {},
   "source": [
    "# 와인 품질 예측"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "18ac6865",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2]\n",
      "(178, 13) (178,)\n",
      "[[1.181e+01 2.120e+00 2.740e+00 ... 9.500e-01 2.260e+00 6.250e+02]\n",
      " [1.317e+01 2.590e+00 2.370e+00 ... 6.000e-01 1.620e+00 8.400e+02]\n",
      " [1.371e+01 1.860e+00 2.360e+00 ... 1.110e+00 4.000e+00 1.035e+03]\n",
      " ...\n",
      " [1.345e+01 3.700e+00 2.600e+00 ... 8.500e-01 1.560e+00 6.950e+02]\n",
      " [1.293e+01 2.810e+00 2.700e+00 ... 7.700e-01 2.310e+00 6.000e+02]\n",
      " [1.184e+01 8.900e-01 2.580e+00 ... 7.900e-01 3.080e+00 5.200e+02]] [1 2 0 1 1 2 1 1 2 2 0 0 0 0 1 0 0 1 2 1 0 2 0 1 1 1 2 2 1 1 1 1 0 2 1 0 1\n",
      " 1 1 0 2 2 1 1 0 2 0 0 1 1 0 1 1 0 2 2 0 0 2 0 0 1 0 1 2 2 1 2 0 1 2 1 1 1\n",
      " 1 1 0 0 2 1 2 0 1 0 2 1 1 1 2 0 1 2 2 0 1 0 0 0 0 2 2 0 2 2 1 1 1 2 1 1 0\n",
      " 1 2 2 2 0 0 1 1 1 0 2 0 1 1 1 1 1 2 1 1 1 1 2 2 1 0 1 0 2 2 1]\n",
      "[[1.376000e+01 1.530000e+00 2.700000e+00 1.950000e+01 1.320000e+02\n",
      "  2.950000e+00 2.740000e+00 5.000000e-01 1.350000e+00 5.400000e+00\n",
      "  1.250000e+00 3.000000e+00 1.235000e+03]\n",
      " [1.225000e+01 4.720000e+00 2.540000e+00 2.100000e+01 8.900000e+01\n",
      "  1.380000e+00 4.700000e-01 5.300000e-01 8.000000e-01 3.850000e+00\n",
      "  7.500000e-01 1.270000e+00 7.200000e+02]\n",
      " [1.388000e+01 1.890000e+00 2.590000e+00 1.500000e+01 1.010000e+02\n",
      "  3.250000e+00 3.560000e+00 1.700000e-01 1.700000e+00 5.430000e+00\n",
      "  8.800000e-01 3.560000e+00 1.095000e+03]\n",
      " [1.438000e+01 1.870000e+00 2.380000e+00 1.200000e+01 1.020000e+02\n",
      "  3.300000e+00 3.640000e+00 2.900000e-01 2.960000e+00 7.500000e+00\n",
      "  1.200000e+00 3.000000e+00 1.547000e+03]\n",
      " [1.375000e+01 1.730000e+00 2.410000e+00 1.600000e+01 8.900000e+01\n",
      "  2.600000e+00 2.760000e+00 2.900000e-01 1.810000e+00 5.600000e+00\n",
      "  1.150000e+00 2.900000e+00 1.320000e+03]\n",
      " [1.207000e+01 2.160000e+00 2.170000e+00 2.100000e+01 8.500000e+01\n",
      "  2.600000e+00 2.650000e+00 3.700000e-01 1.350000e+00 2.760000e+00\n",
      "  8.600000e-01 3.280000e+00 3.780000e+02]\n",
      " [1.272000e+01 1.750000e+00 2.280000e+00 2.250000e+01 8.400000e+01\n",
      "  1.380000e+00 1.760000e+00 4.800000e-01 1.630000e+00 3.300000e+00\n",
      "  8.800000e-01 2.420000e+00 4.880000e+02]\n",
      " [1.311000e+01 1.010000e+00 1.700000e+00 1.500000e+01 7.800000e+01\n",
      "  2.980000e+00 3.180000e+00 2.600000e-01 2.280000e+00 5.300000e+00\n",
      "  1.120000e+00 3.180000e+00 5.020000e+02]\n",
      " [1.305000e+01 1.770000e+00 2.100000e+00 1.700000e+01 1.070000e+02\n",
      "  3.000000e+00 3.000000e+00 2.800000e-01 2.030000e+00 5.040000e+00\n",
      "  8.800000e-01 3.350000e+00 8.850000e+02]\n",
      " [1.422000e+01 3.990000e+00 2.510000e+00 1.320000e+01 1.280000e+02\n",
      "  3.000000e+00 3.040000e+00 2.000000e-01 2.080000e+00 5.100000e+00\n",
      "  8.900000e-01 3.530000e+00 7.600000e+02]\n",
      " [1.242000e+01 2.550000e+00 2.270000e+00 2.200000e+01 9.000000e+01\n",
      "  1.680000e+00 1.840000e+00 6.600000e-01 1.420000e+00 2.700000e+00\n",
      "  8.600000e-01 3.300000e+00 3.150000e+02]\n",
      " [1.204000e+01 4.300000e+00 2.380000e+00 2.200000e+01 8.000000e+01\n",
      "  2.100000e+00 1.750000e+00 4.200000e-01 1.350000e+00 2.600000e+00\n",
      "  7.900000e-01 2.570000e+00 5.800000e+02]\n",
      " [1.277000e+01 2.390000e+00 2.280000e+00 1.950000e+01 8.600000e+01\n",
      "  1.390000e+00 5.100000e-01 4.800000e-01 6.400000e-01 9.899999e+00\n",
      "  5.700000e-01 1.630000e+00 4.700000e+02]\n",
      " [1.307000e+01 1.500000e+00 2.100000e+00 1.550000e+01 9.800000e+01\n",
      "  2.400000e+00 2.640000e+00 2.800000e-01 1.370000e+00 3.700000e+00\n",
      "  1.180000e+00 2.690000e+00 1.020000e+03]\n",
      " [1.305000e+01 2.050000e+00 3.220000e+00 2.500000e+01 1.240000e+02\n",
      "  2.630000e+00 2.680000e+00 4.700000e-01 1.920000e+00 3.580000e+00\n",
      "  1.130000e+00 3.200000e+00 8.300000e+02]\n",
      " [1.245000e+01 3.030000e+00 2.640000e+00 2.700000e+01 9.700000e+01\n",
      "  1.900000e+00 5.800000e-01 6.300000e-01 1.140000e+00 7.500000e+00\n",
      "  6.700000e-01 1.730000e+00 8.800000e+02]\n",
      " [1.437000e+01 1.950000e+00 2.500000e+00 1.680000e+01 1.130000e+02\n",
      "  3.850000e+00 3.490000e+00 2.400000e-01 2.180000e+00 7.800000e+00\n",
      "  8.600000e-01 3.450000e+00 1.480000e+03]\n",
      " [1.299000e+01 1.670000e+00 2.600000e+00 3.000000e+01 1.390000e+02\n",
      "  3.300000e+00 2.890000e+00 2.100000e-01 1.960000e+00 3.350000e+00\n",
      "  1.310000e+00 3.500000e+00 9.850000e+02]\n",
      " [1.287000e+01 4.610000e+00 2.480000e+00 2.150000e+01 8.600000e+01\n",
      "  1.700000e+00 6.500000e-01 4.700000e-01 8.600000e-01 7.650000e+00\n",
      "  5.400000e-01 1.860000e+00 6.250000e+02]\n",
      " [1.421000e+01 4.040000e+00 2.440000e+00 1.890000e+01 1.110000e+02\n",
      "  2.850000e+00 2.650000e+00 3.000000e-01 1.250000e+00 5.240000e+00\n",
      "  8.700000e-01 3.330000e+00 1.080000e+03]\n",
      " [1.253000e+01 5.510000e+00 2.640000e+00 2.500000e+01 9.600000e+01\n",
      "  1.790000e+00 6.000000e-01 6.300000e-01 1.100000e+00 5.000000e+00\n",
      "  8.200000e-01 1.690000e+00 5.150000e+02]\n",
      " [1.406000e+01 1.630000e+00 2.280000e+00 1.600000e+01 1.260000e+02\n",
      "  3.000000e+00 3.170000e+00 2.400000e-01 2.100000e+00 5.650000e+00\n",
      "  1.090000e+00 3.710000e+00 7.800000e+02]\n",
      " [1.358000e+01 2.580000e+00 2.690000e+00 2.450000e+01 1.050000e+02\n",
      "  1.550000e+00 8.400000e-01 3.900000e-01 1.540000e+00 8.660000e+00\n",
      "  7.400000e-01 1.800000e+00 7.500000e+02]\n",
      " [1.483000e+01 1.640000e+00 2.170000e+00 1.400000e+01 9.700000e+01\n",
      "  2.800000e+00 2.980000e+00 2.900000e-01 1.980000e+00 5.200000e+00\n",
      "  1.080000e+00 2.850000e+00 1.045000e+03]\n",
      " [1.200000e+01 1.510000e+00 2.420000e+00 2.200000e+01 8.600000e+01\n",
      "  1.450000e+00 1.250000e+00 5.000000e-01 1.630000e+00 3.600000e+00\n",
      "  1.050000e+00 2.650000e+00 4.500000e+02]\n",
      " [1.187000e+01 4.310000e+00 2.390000e+00 2.100000e+01 8.200000e+01\n",
      "  2.860000e+00 3.030000e+00 2.100000e-01 2.910000e+00 2.800000e+00\n",
      "  7.500000e-01 3.640000e+00 3.800000e+02]\n",
      " [1.349000e+01 3.590000e+00 2.190000e+00 1.950000e+01 8.800000e+01\n",
      "  1.620000e+00 4.800000e-01 5.800000e-01 8.800000e-01 5.700000e+00\n",
      "  8.100000e-01 1.820000e+00 5.800000e+02]\n",
      " [1.363000e+01 1.810000e+00 2.700000e+00 1.720000e+01 1.120000e+02\n",
      "  2.850000e+00 2.910000e+00 3.000000e-01 1.460000e+00 7.300000e+00\n",
      "  1.280000e+00 2.880000e+00 1.310000e+03]\n",
      " [1.368000e+01 1.830000e+00 2.360000e+00 1.720000e+01 1.040000e+02\n",
      "  2.420000e+00 2.690000e+00 4.200000e-01 1.970000e+00 3.840000e+00\n",
      "  1.230000e+00 2.870000e+00 9.900000e+02]\n",
      " [1.320000e+01 1.780000e+00 2.140000e+00 1.120000e+01 1.000000e+02\n",
      "  2.650000e+00 2.760000e+00 2.600000e-01 1.280000e+00 4.380000e+00\n",
      "  1.050000e+00 3.400000e+00 1.050000e+03]\n",
      " [1.373000e+01 1.500000e+00 2.700000e+00 2.250000e+01 1.010000e+02\n",
      "  3.000000e+00 3.250000e+00 2.900000e-01 2.380000e+00 5.700000e+00\n",
      "  1.190000e+00 2.710000e+00 1.285000e+03]\n",
      " [1.237000e+01 9.400000e-01 1.360000e+00 1.060000e+01 8.800000e+01\n",
      "  1.980000e+00 5.700000e-01 2.800000e-01 4.200000e-01 1.950000e+00\n",
      "  1.050000e+00 1.820000e+00 5.200000e+02]\n",
      " [1.387000e+01 1.900000e+00 2.800000e+00 1.940000e+01 1.070000e+02\n",
      "  2.950000e+00 2.970000e+00 3.700000e-01 1.760000e+00 4.500000e+00\n",
      "  1.250000e+00 3.400000e+00 9.150000e+02]\n",
      " [1.286000e+01 1.350000e+00 2.320000e+00 1.800000e+01 1.220000e+02\n",
      "  1.510000e+00 1.250000e+00 2.100000e-01 9.400000e-01 4.100000e+00\n",
      "  7.600000e-01 1.290000e+00 6.300000e+02]\n",
      " [1.340000e+01 3.910000e+00 2.480000e+00 2.300000e+01 1.020000e+02\n",
      "  1.800000e+00 7.500000e-01 4.300000e-01 1.410000e+00 7.300000e+00\n",
      "  7.000000e-01 1.560000e+00 7.500000e+02]\n",
      " [1.382000e+01 1.750000e+00 2.420000e+00 1.400000e+01 1.110000e+02\n",
      "  3.880000e+00 3.740000e+00 3.200000e-01 1.870000e+00 7.050000e+00\n",
      "  1.010000e+00 3.260000e+00 1.190000e+03]] [0 2 0 0 0 1 1 1 0 0 1 1 2 0 0 2 0 1 2 0 2 0 2 0 1 1 2 0 0 0 0 1 0 2 2 0]\n",
      "[[0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 1. 0.]] [[1. 0. 0.]\n",
      " [0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [1. 0. 0.]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_wine\n",
    "import numpy as np\n",
    "wine = load_wine()\n",
    "x = wine['data']\n",
    "y = wine['target']\n",
    "print(np.unique(y))\n",
    "print(x.shape,y.shape)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.2)\n",
    "\n",
    "print(x_train,y_train)\n",
    "print(x_test,y_test)\n",
    "\n",
    "from keras.utils import to_categorical\n",
    "y_train = to_categorical(y_train)\n",
    "y_test = to_categorical(y_test)\n",
    "print(y_train,y_test)\n",
    "\n",
    "# z점수표준화\n",
    "import numpy as np\n",
    "def zscore_standize(x):\n",
    "    return (x-x.mean(0))/x.std(0)\n",
    "\n",
    "x_train = np.apply_along_axis(zscore_standize,0,x_train)\n",
    "x_test = np.apply_along_axis(zscore_standize,0,x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6c6495b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 0.9604 - accuracy: 0.5710 - val_loss: 0.7635 - val_accuracy: 0.8611\n",
      "Epoch 2/100\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.7859 - accuracy: 0.7611 - val_loss: 0.6291 - val_accuracy: 0.8889\n",
      "Epoch 3/100\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.5784 - accuracy: 0.8876 - val_loss: 0.5125 - val_accuracy: 0.8889\n",
      "Epoch 4/100\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.4609 - accuracy: 0.9406 - val_loss: 0.4180 - val_accuracy: 0.9167\n",
      "Epoch 5/100\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.3445 - accuracy: 0.8941 - val_loss: 0.3400 - val_accuracy: 0.9167\n",
      "Epoch 6/100\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.2678 - accuracy: 0.9407 - val_loss: 0.2818 - val_accuracy: 0.9167\n",
      "Epoch 7/100\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.1883 - accuracy: 0.9791 - val_loss: 0.2412 - val_accuracy: 0.9167\n",
      "Epoch 8/100\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.1666 - accuracy: 0.9808 - val_loss: 0.2128 - val_accuracy: 0.9167\n",
      "Epoch 9/100\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.1370 - accuracy: 0.9700 - val_loss: 0.1901 - val_accuracy: 0.9444\n",
      "Epoch 10/100\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.1000 - accuracy: 0.9873 - val_loss: 0.1761 - val_accuracy: 0.9444\n",
      "Epoch 11/100\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.0909 - accuracy: 0.9964 - val_loss: 0.1675 - val_accuracy: 0.9444\n",
      "Epoch 12/100\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.0865 - accuracy: 0.9814 - val_loss: 0.1666 - val_accuracy: 0.9444\n",
      "Epoch 13/100\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.0937 - accuracy: 0.9964 - val_loss: 0.1651 - val_accuracy: 0.9444\n",
      "Epoch 14/100\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.0583 - accuracy: 0.9940 - val_loss: 0.1650 - val_accuracy: 0.9444\n",
      "Epoch 15/100\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.0533 - accuracy: 0.9977 - val_loss: 0.1740 - val_accuracy: 0.9167\n",
      "2/2 [==============================] - 0s 1000us/step - loss: 0.0372 - accuracy: 0.9930\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.layers import Dense, Flatten, Input,Dropout\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(units=64,activation='relu',input_dim=13))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(units=128,activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(units=3,activation='softmax'))\n",
    "\n",
    "\n",
    "early_stopping = EarlyStopping()\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "# sgd\n",
    "\n",
    "\n",
    "\n",
    "model.fit(x_train,y_train,epochs=100,batch_size=32, validation_data=(x_test, y_test),callbacks=[early_stopping]) # 테스트에 대한 \n",
    "loss_and_metrics = model.evaluate(x_train,y_train,batch_size=100) # 평가지표?\n",
    "\n",
    "classes=model.predict(x_train,batch_size=128) # 예측한 결과 y_hat이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04e9d70b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
